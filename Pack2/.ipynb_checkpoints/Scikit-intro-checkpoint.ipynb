{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made for \"Data Analysis for Genomics Workshop\" (DAGWS). \n",
    "Tran Bich Ngoc CAO, ENS Paris, August 2020.\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licence Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br /> This work is protected by the term of <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Licence Creative Commons Attribution - NonCommercial-ShareAlike 4.0 International </a>. Please cite the source in case of re-distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/logo.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arthur Samuel (IBM engineer): In 1956 he challenged himself to teach the IBM 701 to beat him at checkers. In 1962 the program beat the Connecticut champion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Automatic learning: an intro__* \n",
    "\n",
    "Two common definitions:\n",
    "\n",
    "- Arthur Samuel (1959): * Field of study which gives computers the ability to learn without being explicitly programmed *.\n",
    "\n",
    "- Tom Mitchell (1998): * A computer program is said to learn from experience E in relation to a category of tasks T and measure performance P, if its performance on tasks T, as measured by P, improves with experience E. *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised or Unsupervised Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/supervise.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/unsupervised.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supervised learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"fig/ML_explained.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/regression-vs-classification-in-machine-learning.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside, we have also  *Semi-supervised* -\n",
    "     *Regression/Classifications with missing annotations* (not in scope of this WS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Scikit-learn Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still wonder what the package does for you, here is a list of things (in order) that sklearn can do (!) a Swiss-knife, isn't it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Organize the data in the form of feature matrix + target vector\n",
    "- Preprocessing the data, standardize and scale\n",
    "- Splitting the data into train and test sets\n",
    "- Choose a model class to test and import the appropriate class from the API\n",
    "- Choose the model parameters and create an instance this class with the desired parameter values, testing hyperparameters and choose the best\n",
    "- \"Fitter\" (learn) the model with your data by calling the fit () method of the chosen class\n",
    "- Use the model: make predictions by applying it to new data\n",
    "- Evaluate the model and hyperparameters\n",
    "- All of the steps, moreover, can be chained into a single pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry, each of the step will be broken down for you to digest :) Let's look at this diagram!\n",
    "All steps in either supervised or unsupervised learning with Scikit-learn is quite similar, systemic, thus easy to remember!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question you will ask yourself during the process:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which model to choose?\n",
    "- How do I split my data to avoid overfitting/ underfitting?\n",
    "- Which hyperparameters?\n",
    "- Which parameters?\n",
    "- How can I access my model ? any metrics? (accuracy, precision, ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/overfitting.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of Overfitting the data. The \"Model Complexity\" is larger in <font color='green'>green</font> curve than __black__ curve, the model learns well on the `train_set` but not on the `test_set`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   *Why do you think we need to split the data?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  *What is hyperparameter?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the parameters of the model and create an instance this class with the desired parameter values.\n",
    "\n",
    "_\"hyperparameters\": This matches the parameters specified ** after ** choosing the model but ** before ** learning the model.\n",
    "\n",
    "Examples of hyperparameters:\n",
    "- Regularization parameter\n",
    "- Standardization of the model\n",
    "- Number of components of the model (e.g. degree of polynomial)\n",
    "- Standardization of \"features\"?\n",
    "- Fitter the interception?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Fitter\" (learn) the model with your data by calling the `fit ()` method of the chosen class\n",
    "\n",
    "Now we are ready to learn our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This calculates the model parameters that determine the model itself. This distinguishes these parameters from _hyperparameters_ defined before learning. The model parameters calculated through training are denoted by convention by the character `_` at the end of their name:` model.coef_`, `model.intercept_`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Navigate yourself when it comes to choose Algorithm: Cheatsheet!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/ml_map.png\" size=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading:\n",
    "[Machine Learning in genomics](https://towardsdatascience.com/machine-learning-for-genomics-c02270a51795): very promising, need to be explored!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
